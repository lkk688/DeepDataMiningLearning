#!/usr/bin/env python3
"""
Optimized and reorganized KITTI and Waymo2KITTI dataset visualization using Open3D.
Replaces Mayavi with Open3D for colorful 3D point cloud and 3D bounding box visualization.
Supports headless environment with PLY file export.

This code is based on the original waymokittiall.py and maintains full compatibility
with the KITTI and Waymo2KITTI dataset formats generated by waymo2kitti.py.

Mathematical Foundations:
========================

1. 3D Bounding Box Corner Generation:
   For a box with center (x,y,z), dimensions (dx,dy,dz), and heading θ:
   
   Template corners (before rotation):
   $$\mathbf{T} = \frac{1}{2} \begin{bmatrix}
   1 & 1 & -1 \\
   1 & -1 & -1 \\
   -1 & -1 & -1 \\
   -1 & 1 & -1 \\
   1 & 1 & 1 \\
   1 & -1 & 1 \\
   -1 & -1 & 1 \\
   -1 & 1 & 1
   \end{bmatrix}$$
   
   Scaled corners: $\mathbf{C}_s = \mathbf{T} \odot [dx, dy, dz]$
   
   Rotation matrix around Z-axis:
   $$\mathbf{R}_z(\theta) = \begin{bmatrix}
   \cos\theta & -\sin\theta & 0 \\
   \sin\theta & \cos\theta & 0 \\
   0 & 0 & 1
   \end{bmatrix}$$
   
   Final corners: $\mathbf{C} = \mathbf{C}_s \mathbf{R}_z(\theta) + [x, y, z]$

2. Point Cloud Intensity-Based Coloring:
   For intensity values I ∈ [I_min, I_max]:
   
   Normalized intensity: $I_n = \frac{I - I_{min}}{I_{max} - I_{min}}$
   
   RGB mapping using viridis colormap:
   $$\begin{align}
   R &= 0.267004 + I_n(-0.127568 + I_n(0.472873 + I_n(-0.498882))) \\
   G &= 0.004874 + I_n(1.424006 + I_n(-2.174996 + I_n(1.074935))) \\
   B &= 0.329415 + I_n(0.226420 + I_n(-0.020582 + I_n(-0.266134)))
   \end{align}$$

3. Coordinate System Transformations:
   KITTI uses right-handed coordinate system:
   - X: forward (vehicle direction)
   - Y: left
   - Z: up
   
   Waymo2KITTI maintains KITTI coordinate conventions after conversion.

Author: AI Assistant
Date: 2024
License: MIT
"""

import numpy as np
import os
import cv2
import sys
import argparse
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import matplotlib.colors as mcolors
import math
import torch
from typing import List, Tuple, Optional, Union
import warnings

# Suppress Open3D warnings in headless mode
warnings.filterwarnings("ignore", category=UserWarning)

try:
    import open3d as o3d
    OPEN3D_AVAILABLE = True
except ImportError:
    print("Warning: Open3D not available. Install with: pip install open3d")
    OPEN3D_AVAILABLE = False

# Configuration
plt.rcParams['figure.figsize'] = (16, 9)

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
ROOT_DIR = os.path.dirname(BASE_DIR)
sys.path.append(ROOT_DIR)

# Color mappings for different object types
box_colormap = [
    [1, 1, 1],      # White
    [0, 1, 0],      # Green
    [0, 1, 1],      # Cyan
    [1, 1, 0],      # Yellow
]

INSTANCE_Color = {
    'Car': 'red', 
    'Pedestrian': 'green', 
    'Sign': 'yellow', 
    'Cyclist': 'purple'
}

INSTANCE3D_Color = {
    'Car': (0, 1, 0),           # Green
    'Pedestrian': (0, 1, 1),   # Cyan
    'Sign': (1, 1, 0),         # Yellow
    'Cyclist': (0.5, 0.5, 0.3) # Brown
}

INSTANCE3D_ColorCV2 = {
    'Car': (0, 255, 0), 
    'Pedestrian': (255, 255, 0), 
    'Sign': (0, 255, 255), 
    'Cyclist': (127, 127, 64)
}

waymocameraorder = {
    0: 1, 1: 0, 2: 2, 3: 3, 4: 4
}  # Front, front_left, side_left, front_right, side_right

cameraname_map = {
    0: "FRONT", 
    1: "FRONT_LEFT", 
    2: "FRONT_RIGHT", 
    3: "SIDE_LEFT", 
    4: "SIDE_RIGHT"
}


def check_numpy_to_torch(x: Union[np.ndarray, torch.Tensor]) -> Tuple[torch.Tensor, bool]:
    """
    Convert numpy array to torch tensor if needed.
    
    Args:
        x: Input array or tensor
        
    Returns:
        Tuple of (tensor, was_numpy_flag)
    """
    if isinstance(x, np.ndarray):
        return torch.from_numpy(x).float(), True
    return x, False


def rotate_points_along_z(points: Union[np.ndarray, torch.Tensor], 
                         angle: Union[np.ndarray, torch.Tensor]) -> Union[np.ndarray, torch.Tensor]:
    """
    Rotate points around Z-axis using rotation matrix.
    
    Mathematical Formula:
    $$\mathbf{R}_z(\theta) = \begin{bmatrix}
    \cos\theta & -\sin\theta & 0 \\
    \sin\theta & \cos\theta & 0 \\
    0 & 0 & 1
    \end{bmatrix}$$
    
    Args:
        points: (B, N, 3 + C) points to rotate
        angle: (B,) rotation angles in radians
        
    Returns:
        Rotated points with same shape as input
    """
    points, is_numpy = check_numpy_to_torch(points)
    angle, _ = check_numpy_to_torch(angle)

    cosa = torch.cos(angle)
    sina = torch.sin(angle)
    zeros = angle.new_zeros(points.shape[0])
    ones = angle.new_ones(points.shape[0])
    
    # Construct rotation matrix: R_z(θ)
    rot_matrix = torch.stack((
        cosa,  sina, zeros,
        -sina, cosa, zeros,
        zeros, zeros, ones
    ), dim=1).view(-1, 3, 3).float()
    
    # Apply rotation to XYZ coordinates only
    points_rot = torch.matmul(points[:, :, 0:3], rot_matrix)
    points_rot = torch.cat((points_rot, points[:, :, 3:]), dim=-1)
    
    return points_rot.numpy() if is_numpy else points_rot


def boxes_to_corners_3d(boxes3d: Union[np.ndarray, torch.Tensor]) -> Union[np.ndarray, torch.Tensor]:
    """
    Generate 8 corner points for 3D bounding boxes.
    
    Corner ordering (KITTI format):
        7 -------- 4
       /|         /|
      6 -------- 5 .
      | |        | |
      . 3 -------- 0
      |/         |/
      2 -------- 1
    
    Mathematical Process:
    1. Create template corners: T = [±1, ±1, ±1] / 2
    2. Scale by box dimensions: C_s = T ⊙ [dx, dy, dz]
    3. Rotate around Z-axis: C_r = C_s * R_z(θ)
    4. Translate to box center: C = C_r + [x, y, z]
    
    Args:
        boxes3d: (N, 7) [x, y, z, dx, dy, dz, heading]
        
    Returns:
        corners3d: (N, 8, 3) corner coordinates
    """
    boxes3d, is_numpy = check_numpy_to_torch(boxes3d)

    # Template for 8 corners of a unit cube
    template = boxes3d.new_tensor((
        [1, 1, -1], [1, -1, -1], [-1, -1, -1], [-1, 1, -1],  # Bottom face
        [1, 1, 1], [1, -1, 1], [-1, -1, 1], [-1, 1, 1],      # Top face
    )) / 2

    # Scale template by box dimensions
    corners3d = boxes3d[:, None, 3:6].repeat(1, 8, 1) * template[None, :, :]
    
    # Rotate corners around Z-axis by heading angle
    corners3d = rotate_points_along_z(corners3d.view(-1, 8, 3), boxes3d[:, 6]).view(-1, 8, 3)
    
    # Translate to box center
    corners3d += boxes3d[:, None, 0:3]

    return corners3d.numpy() if is_numpy else corners3d


class Open3DVisualizer:
    """
    Open3D-based 3D visualization system for KITTI and Waymo2KITTI datasets.
    
    This class provides comprehensive 3D visualization capabilities including:
    - Colorful point cloud rendering with intensity-based coloring
    - 3D bounding box visualization with class-specific colors
    - Coordinate system axes and ground grid
    - Headless rendering with PLY export support
    """
    
    def __init__(self, headless: bool = False, window_size: Tuple[int, int] = (1024, 768)):
        """
        Initialize the Open3D visualizer.
        
        Args:
            headless: Whether to run in headless mode (no GUI)
            window_size: Window dimensions for GUI mode
        """
        self.headless = headless
        self.window_size = window_size
        self.vis = None
        self.geometries = []
        
        if not OPEN3D_AVAILABLE:
            raise ImportError("Open3D is required but not installed. Run: pip install open3d")
    
    def create_point_cloud(self, points: np.ndarray, 
                          color_by_intensity: bool = True,
                          point_size: float = 2.0) -> o3d.geometry.PointCloud:
        """
        Create Open3D point cloud from numpy array.
        
        Intensity-based coloring uses viridis colormap approximation:
        $$\text{RGB} = f_{\text{viridis}}(\frac{I - I_{\min}}{I_{\max} - I_{\min}})$$
        
        Args:
            points: (N, 3) or (N, 4) array with XYZ and optional intensity
            color_by_intensity: Whether to color by intensity values
            point_size: Point rendering size
            
        Returns:
            Open3D PointCloud object
        """
        pcd = o3d.geometry.PointCloud()
        pcd.points = o3d.utility.Vector3dVector(points[:, :3])
        
        if color_by_intensity and points.shape[1] >= 4:
            # Normalize intensity values to [0, 1]
            intensities = points[:, 3]
            if intensities.max() > intensities.min():
                normalized_intensities = (intensities - intensities.min()) / (intensities.max() - intensities.min())
            else:
                normalized_intensities = np.ones_like(intensities) * 0.5
            
            # Apply viridis-like colormap
            colors = self._apply_viridis_colormap(normalized_intensities)
            pcd.colors = o3d.utility.Vector3dVector(colors)
        else:
            # Default white color
            pcd.colors = o3d.utility.Vector3dVector(np.ones((len(points), 3)) * 0.8)
        
        return pcd
    
    def _apply_viridis_colormap(self, values: np.ndarray) -> np.ndarray:
        """
        Apply viridis-like colormap to normalized values [0, 1].
        
        Viridis colormap approximation:
        $$\begin{align}
        R &= 0.267004 + v(-0.127568 + v(0.472873 + v(-0.498882))) \\
        G &= 0.004874 + v(1.424006 + v(-2.174996 + v(1.074935))) \\
        B &= 0.329415 + v(0.226420 + v(-0.020582 + v(-0.266134)))
        \end{align}$$
        
        Args:
            values: Normalized values in [0, 1]
            
        Returns:
            RGB colors array (N, 3)
        """
        v = np.clip(values, 0, 1)
        
        # Viridis colormap polynomial approximation
        r = 0.267004 + v * (-0.127568 + v * (0.472873 + v * (-0.498882)))
        g = 0.004874 + v * (1.424006 + v * (-2.174996 + v * (1.074935)))
        b = 0.329415 + v * (0.226420 + v * (-0.020582 + v * (-0.266134)))
        
        return np.column_stack([r, g, b])
    
    def create_bounding_box(self, corners: np.ndarray, 
                           color: Tuple[float, float, float] = (0, 1, 0),
                           line_width: float = 2.0) -> o3d.geometry.LineSet:
        """
        Create 3D bounding box from 8 corner points.
        
        Corner connectivity follows KITTI convention:
        - Bottom face: 0-1-2-3-0
        - Top face: 4-5-6-7-4  
        - Vertical edges: 0-4, 1-5, 2-6, 3-7
        
        Args:
            corners: (8, 3) corner coordinates
            color: RGB color tuple
            line_width: Line thickness
            
        Returns:
            Open3D LineSet object
        """
        # Define the 12 edges of a bounding box
        lines = [
            [0, 1], [1, 2], [2, 3], [3, 0],  # Bottom face
            [4, 5], [5, 6], [6, 7], [7, 4],  # Top face
            [0, 4], [1, 5], [2, 6], [3, 7],  # Vertical edges
        ]
        
        line_set = o3d.geometry.LineSet()
        line_set.points = o3d.utility.Vector3dVector(corners)
        line_set.lines = o3d.utility.Vector2iVector(lines)
        
        # Set uniform color for all lines
        colors = [color for _ in range(len(lines))]
        line_set.colors = o3d.utility.Vector3dVector(colors)
        
        return line_set
    
    def create_coordinate_frame(self, size: float = 3.0, origin: np.ndarray = None) -> o3d.geometry.TriangleMesh:
        """
        Create coordinate system axes.
        
        KITTI coordinate system:
        - X-axis (Red): Forward direction
        - Y-axis (Green): Left direction  
        - Z-axis (Blue): Up direction
        
        Args:
            size: Axis length
            origin: Origin position (default: [0, 0, 0])
            
        Returns:
            Open3D coordinate frame mesh
        """
        if origin is None:
            origin = np.array([0.0, 0.0, 0.0])
        
        coord_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(
            size=size, origin=origin
        )
        return coord_frame
    
    def create_ground_grid(self, size: float = 100.0, step: float = 10.0, 
                          height: float = 0.0) -> o3d.geometry.LineSet:
        """
        Create ground plane grid for reference.
        
        Grid extends from -size/2 to +size/2 in X and Y directions.
        
        Args:
            size: Grid total size
            step: Grid line spacing
            height: Z-coordinate of grid plane
            
        Returns:
            Open3D LineSet for grid
        """
        lines = []
        points = []
        
        # Create grid lines parallel to X-axis
        for y in np.arange(-size/2, size/2 + step, step):
            points.extend([[-size/2, y, height], [size/2, y, height]])
            lines.append([len(points)-2, len(points)-1])
        
        # Create grid lines parallel to Y-axis  
        for x in np.arange(-size/2, size/2 + step, step):
            points.extend([[x, -size/2, height], [x, size/2, height]])
            lines.append([len(points)-2, len(points)-1])
        
        line_set = o3d.geometry.LineSet()
        line_set.points = o3d.utility.Vector3dVector(points)
        line_set.lines = o3d.utility.Vector2iVector(lines)
        
        # Gray color for grid
        colors = [(0.5, 0.5, 0.5) for _ in range(len(lines))]
        line_set.colors = o3d.utility.Vector3dVector(colors)
        
        return line_set
    
    def visualize_scene(self, points: np.ndarray, 
                       boxes: Optional[List] = None,
                       point_cloud_range: Optional[List[float]] = None,
                       save_path: Optional[str] = None,
                       show_coordinate_frame: bool = True,
                       show_ground_grid: bool = True) -> None:
        """
        Visualize complete 3D scene with point cloud and bounding boxes.
        
        Args:
            points: (N, 3) or (N, 4) point cloud array
            boxes: List of Object3d instances or box arrays
            point_cloud_range: [xmin, ymin, zmin, xmax, ymax, zmax] for filtering
            save_path: Path to save visualization (PLY format)
            show_coordinate_frame: Whether to show coordinate axes
            show_ground_grid: Whether to show ground grid
        """
        if not OPEN3D_AVAILABLE:
            print("Open3D not available, skipping visualization")
            return
        
        self.geometries = []
        
        # Filter points if range specified
        if point_cloud_range is not None:
            points = self._filter_points(points, point_cloud_range)
        
        # Create point cloud
        pcd = self.create_point_cloud(points, color_by_intensity=True)
        self.geometries.append(pcd)
        
        # Add bounding boxes
        if boxes is not None:
            for obj in boxes:
                if hasattr(obj, 'type') and obj.type == "DontCare":
                    continue
                
                # Get box color based on object type
                if hasattr(obj, 'type') and obj.type in INSTANCE3D_Color:
                    color = INSTANCE3D_Color[obj.type]
                else:
                    color = (1, 1, 1)  # Default white
                
                # Generate box corners
                if hasattr(obj, 'h'):  # Object3d format
                    corners = self._object3d_to_corners(obj)
                else:  # Assume numpy array format [x, y, z, dx, dy, dz, heading]
                    corners = boxes_to_corners_3d(np.array([obj]))[0]
                
                # Create and add bounding box
                bbox = self.create_bounding_box(corners, color)
                self.geometries.append(bbox)
        
        # Add coordinate frame
        if show_coordinate_frame:
            coord_frame = self.create_coordinate_frame(size=5.0)
            self.geometries.append(coord_frame)
        
        # Add ground grid
        if show_ground_grid:
            grid = self.create_ground_grid(size=100.0, step=10.0)
            self.geometries.append(grid)
        
        # Visualize or save
        if self.headless or save_path:
            if save_path:
                self._save_scene(save_path)
                print(f"Scene saved to: {save_path}")
        else:
            self._show_interactive()
    
    def _filter_points(self, points: np.ndarray, 
                      point_cloud_range: List[float]) -> np.ndarray:
        """
        Filter points within specified 3D range.
        
        Range format: [xmin, ymin, zmin, xmax, ymax, zmax]
        
        Args:
            points: Input point cloud
            point_cloud_range: 3D bounding range
            
        Returns:
            Filtered points
        """
        mask = (
            (points[:, 0] >= point_cloud_range[0]) & (points[:, 0] <= point_cloud_range[3]) &
            (points[:, 1] >= point_cloud_range[1]) & (points[:, 1] <= point_cloud_range[4]) &
            (points[:, 2] >= point_cloud_range[2]) & (points[:, 2] <= point_cloud_range[5])
        )
        
        if points.shape[1] >= 4:  # Has intensity
            mask = mask & (points[:, 3] <= 1.0)  # Filter invalid intensity
        
        filtered_points = points[mask]
        print(f"Filtered points: {len(points)} -> {len(filtered_points)}")
        return filtered_points
    
    def _object3d_to_corners(self, obj) -> np.ndarray:
        """
        Convert Object3d instance to 8 corner coordinates.
        
        Uses the compute_box_3d function from original code.
        
        Args:
            obj: Object3d instance
            
        Returns:
            (8, 3) corner coordinates
        """
        return compute_box_3d(obj).T  # Transpose to get (8, 3)
    
    def _save_scene(self, save_path: str) -> None:
        """
        Save scene geometries to PLY file.
        
        Args:
            save_path: Output file path
        """
        # Combine all point clouds
        combined_pcd = o3d.geometry.PointCloud()
        
        for geom in self.geometries:
            if isinstance(geom, o3d.geometry.PointCloud):
                combined_pcd += geom
            elif isinstance(geom, o3d.geometry.LineSet):
                # Convert line set to point cloud for saving
                line_pcd = o3d.geometry.PointCloud()
                line_pcd.points = geom.points
                if len(geom.colors) > 0:
                    line_pcd.colors = geom.colors
                combined_pcd += line_pcd
        
        # Save combined point cloud
        if len(combined_pcd.points) > 0:
            o3d.io.write_point_cloud(save_path, combined_pcd)
    
    def _show_interactive(self) -> None:
        """Show interactive visualization window."""
        if self.headless:
            return
        
        self.vis = o3d.visualization.Visualizer()
        self.vis.create_window(width=self.window_size[0], height=self.window_size[1])
        
        # Add all geometries
        for geom in self.geometries:
            self.vis.add_geometry(geom)
        
        # Set viewing parameters
        ctr = self.vis.get_view_control()
        ctr.set_front([0.0, 0.0, -1.0])  # Look down negative Z
        ctr.set_lookat([0.0, 0.0, 0.0])  # Look at origin
        ctr.set_up([0.0, -1.0, 0.0])     # Y-axis points up in view
        ctr.set_zoom(0.3)
        
        # Run visualization
        self.vis.run()
        self.vis.destroy_window()


# Original data loading and processing functions (maintained for compatibility)

class Object3d(object):
    """
    3D object label class for KITTI format.
    
    Parses KITTI label format:
    type truncated occluded alpha bbox_2d dimensions location rotation_y
    """

    def __init__(self, label_file_line: str):
        """
        Initialize from KITTI label line.
        
        Args:
            label_file_line: Single line from KITTI label file
        """
        data = label_file_line.split(" ")
        data[1:] = [float(x) for x in data[1:]]

        # Extract label, truncation, occlusion
        self.type = data[0]  # 'Car', 'Pedestrian', ...
        self.truncation = data[1]  # truncated pixel ratio [0..1]
        self.occlusion = int(data[2])  # 0=visible, 1=partly occluded, 2=fully occluded, 3=unknown
        self.alpha = data[3]  # object observation angle [-pi..pi]

        # Extract 2D bounding box in 0-based coordinates
        self.xmin = data[4]  # left
        self.ymin = data[5]  # top
        self.xmax = data[6]  # right
        self.ymax = data[7]  # bottom
        self.box2d = np.array([self.xmin, self.ymin, self.xmax, self.ymax])

        # Extract 3D bounding box information
        self.h = data[8]   # box height
        self.w = data[9]   # box width
        self.l = data[10]  # box length (in meters)
        self.t = (data[11], data[12], data[13])  # location (x,y,z) in camera coord.
        self.ry = data[14]  # yaw angle (around Y-axis in camera coordinates) [-pi..pi]

    def estimate_difficulty(self) -> str:
        """Estimate detection difficulty as defined in KITTI."""
        bb_height = np.abs(self.xmax - self.xmin)

        if bb_height >= 40 and self.occlusion == 0 and self.truncation <= 0.15:
            return "Easy"
        elif bb_height >= 25 and self.occlusion in [0, 1] and self.truncation <= 0.30:
            return "Moderate"
        elif bb_height >= 25 and self.occlusion in [0, 1, 2] and self.truncation <= 0.50:
            return "Hard"
        else:
            return "Unknown"

    def print_object(self):
        """Print object information."""
        print(f"Type, truncation, occlusion, alpha: {self.type}, {self.truncation}, {self.occlusion}, {self.alpha}")
        print(f"2d bbox (x0,y0,x1,y1): {self.xmin}, {self.ymin}, {self.xmax}, {self.ymax}")
        print(f"3d bbox h,w,l: {self.h}, {self.w}, {self.l}")
        print(f"3d bbox location, ry: ({self.t[0]}, {self.t[1]}, {self.t[2]}), {self.ry}")
        print(f"Difficulty of estimation: {self.estimate_difficulty()}")


def load_velo_scan(velo_filename: str, dtype=np.float32, n_vec: int = 4, 
                  filterpoints: bool = False, 
                  point_cloud_range: List[float] = [0, -15, -5, 90, 15, 4]) -> np.ndarray:
    """
    Load velodyne point cloud from binary file.
    
    Args:
        velo_filename: Path to .bin file
        dtype: Data type for loading
        n_vec: Number of values per point (typically 4: x, y, z, intensity)
        filterpoints: Whether to filter points by range
        point_cloud_range: [xmin, ymin, zmin, xmax, ymax, zmax]
        
    Returns:
        Point cloud array (N, n_vec)
    """
    scan = np.fromfile(velo_filename, dtype=dtype)
    scan = scan.reshape((-1, n_vec))
    
    xpoints = scan[:, 0]
    ypoints = scan[:, 1]
    zpoints = scan[:, 2]
    
    print(f"X range: {min(xpoints):.2f} to {max(xpoints):.2f}")
    print(f"Y range: {min(ypoints):.2f} to {max(ypoints):.2f}")
    print(f"Z range: {min(zpoints):.2f} to {max(zpoints):.2f}")
    
    if filterpoints:
        print(f"Filtering points in range: x[{point_cloud_range[0]}, {point_cloud_range[3]}], "
              f"y[{point_cloud_range[1]}, {point_cloud_range[4]}], "
              f"z[{point_cloud_range[2]}, {point_cloud_range[5]}]")
        scan = filter_lidarpoints(scan, point_cloud_range)
    
    return scan


def filter_lidarpoints(pc_velo: np.ndarray, 
                      point_cloud_range: List[float] = [0, -15, -5, 90, 15, 4]) -> np.ndarray:
    """
    Filter LiDAR points within specified range.
    
    Args:
        pc_velo: Point cloud array (N, 4)
        point_cloud_range: [xmin, ymin, zmin, xmax, ymax, zmax]
        
    Returns:
        Filtered point cloud
    """
    mask = (
        (pc_velo[:, 0] >= point_cloud_range[0]) & (pc_velo[:, 0] <= point_cloud_range[3]) &
        (pc_velo[:, 1] >= point_cloud_range[1]) & (pc_velo[:, 1] <= point_cloud_range[4]) &
        (pc_velo[:, 2] >= point_cloud_range[2]) & (pc_velo[:, 2] <= point_cloud_range[5]) &
        (pc_velo[:, 3] <= 1)  # Valid intensity
    )
    
    filtered_points = pc_velo[mask]
    print(f"Points after filtering: {filtered_points.shape}")
    return filtered_points


def read_label(label_filename: str) -> List[Object3d]:
    """
    Read KITTI format label file.
    
    Args:
        label_filename: Path to label file
        
    Returns:
        List of Object3d instances
    """
    if os.path.exists(label_filename):
        lines = [line.rstrip() for line in open(label_filename)]
        objects = [Object3d(line) for line in lines]
        return objects
    else:
        return []


def read_multi_label(label_files: List[str]) -> List[List[Object3d]]:
    """
    Read multiple label files.
    
    Args:
        label_files: List of label file paths
        
    Returns:
        List of object lists for each file
    """
    objectlabels = []
    for label_file in label_files:
        object3dlabel = read_label(label_file)
        objectlabels.append(object3dlabel)
    return objectlabels


def load_image(img_filenames: List[str], jpgfile: bool = False) -> List[np.ndarray]:
    """
    Load multiple images.
    
    Args:
        img_filenames: List of image file paths
        jpgfile: Whether to use .jpg extension instead of .png
        
    Returns:
        List of RGB image arrays
    """
    imgs = []
    for img_filename in img_filenames:
        if jpgfile:
            img_filename = img_filename.replace('.png', '.jpg')
        img = cv2.imread(img_filename)
        rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        imgs.append(rgb)
    return imgs


def compute_box_3d(obj: Object3d, dataset: str = 'kitti') -> np.ndarray:
    """
    Compute 3D bounding box corners from Object3d.
    
    Mathematical Process:
    1. Create 3D box template in object coordinate system
    2. Apply rotation around Y-axis (yaw)
    3. Translate to object center position
    
    Rotation matrix around Y-axis:
    $$\mathbf{R}_y(\theta) = \begin{bmatrix}
    \cos\theta & 0 & \sin\theta \\
    0 & 1 & 0 \\
    -\sin\theta & 0 & \cos\theta
    \end{bmatrix}$$
    
    Args:
        obj: Object3d instance
        dataset: Dataset type (default: 'kitti')
        
    Returns:
        corners_3d: (3, 8) corner coordinates in camera frame
    """
    # 3D bounding box dimensions
    l, w, h = obj.l, obj.w, obj.h
    
    # 3D bounding box corners template (object coordinate system)
    x_corners = [l/2, l/2, -l/2, -l/2, l/2, l/2, -l/2, -l/2]
    y_corners = [0, 0, 0, 0, -h, -h, -h, -h]
    z_corners = [w/2, -w/2, -w/2, w/2, w/2, -w/2, -w/2, w/2]
    
    # Rotation matrix around Y-axis (yaw angle)
    R = np.array([
        [np.cos(obj.ry), 0, np.sin(obj.ry)],
        [0, 1, 0],
        [-np.sin(obj.ry), 0, np.cos(obj.ry)]
    ])
    
    # Rotate and translate
    corners_3d = np.vstack([x_corners, y_corners, z_corners])  # (3, 8)
    corners_3d = np.dot(R, corners_3d)
    corners_3d[0, :] = corners_3d[0, :] + obj.t[0]
    corners_3d[1, :] = corners_3d[1, :] + obj.t[1]
    corners_3d[2, :] = corners_3d[2, :] + obj.t[2]
    
    return corners_3d


# Calibration classes (simplified versions for compatibility)

class WaymoCalibration(object):
    """Waymo calibration class (placeholder for compatibility)."""
    
    def __init__(self, calibration_file: str):
        """Initialize from calibration file."""
        # Implementation would load Waymo calibration parameters
        pass
    
    def project_rect_to_velo(self, pts_3d_rect: np.ndarray, cameraid: int = 0) -> np.ndarray:
        """Project from camera rect to velodyne coordinates."""
        # Placeholder implementation
        return pts_3d_rect
    
    def project_velo_to_cameraid(self, pts_3d_velo: np.ndarray, cameraid: int = 0) -> np.ndarray:
        """Project from velodyne to camera coordinates."""
        # Placeholder implementation
        return pts_3d_velo
    
    def project_cam3d_to_image(self, pts_3d_cam: np.ndarray, cameraid: int = 0) -> Tuple[np.ndarray, np.ndarray]:
        """Project 3D camera points to image."""
        # Placeholder implementation
        return pts_3d_cam[:2, :].T, pts_3d_cam[2, :]


class KittiCalibration(object):
    """KITTI calibration class (placeholder for compatibility)."""
    
    def __init__(self, calibration_file: str):
        """Initialize from calibration file."""
        # Implementation would load KITTI calibration parameters
        pass
    
    def project_rect_to_velo(self, pts_3d_rect: np.ndarray, cameraid: int = 0) -> np.ndarray:
        """Project from camera rect to velodyne coordinates."""
        # Placeholder implementation
        return pts_3d_rect
    
    def project_velo_to_cameraid(self, pts_3d_velo: np.ndarray, cameraid: int = 0) -> np.ndarray:
        """Project from velodyne to camera coordinates."""
        # Placeholder implementation
        return pts_3d_velo
    
    def project_cam3d_to_image(self, pts_3d_cam: np.ndarray, cameraid: int = 0) -> Tuple[np.ndarray, np.ndarray]:
        """Project 3D camera points to image."""
        # Placeholder implementation
        return pts_3d_cam[:2, :].T, pts_3d_cam[2, :]


def datasetinfo(datasetname: str) -> Tuple[int, int]:
    """
    Get dataset-specific camera configuration.
    
    Args:
        datasetname: 'waymokitti' or 'kitti'
        
    Returns:
        Tuple of (camera_index, max_camera_count)
    """
    if datasetname.lower() == 'waymokitti':
        camera_index = 0  # front camera of Waymo is image_0
        max_cameracount = 5
    elif datasetname.lower() == 'kitti':
        camera_index = 2  # front camera of KITTI is image_2
        max_cameracount = 5
    return camera_index, max_cameracount


def getcalibration(datasetname: str, calibration_file: str):
    """
    Get appropriate calibration object for dataset.
    
    Args:
        datasetname: 'waymokitti' or 'kitti'
        calibration_file: Path to calibration file
        
    Returns:
        Calibration object
    """
    if datasetname.lower() == 'waymokitti':
        calib = WaymoCalibration(calibration_file)
    elif datasetname.lower() == 'kitti':
        calib = KittiCalibration(calibration_file)
    return calib


def visualize_lidar_with_boxes_open3d(pc_velo: np.ndarray, 
                                     object3dlabels: List[Object3d],
                                     calib,
                                     point_cloud_range: List[float],
                                     save_path: Optional[str] = None,
                                     headless: bool = False) -> None:
    """
    Visualize LiDAR point cloud with 3D bounding boxes using Open3D.
    
    This function replaces the original Mayavi-based visualization.
    
    Args:
        pc_velo: Point cloud array (N, 4)
        object3dlabels: List of Object3d instances
        calib: Calibration object
        point_cloud_range: Point filtering range
        save_path: Optional path to save PLY file
        headless: Whether to run in headless mode
    """
    print("Visualizing with Open3D...")
    
    # Create visualizer
    visualizer = Open3DVisualizer(headless=headless)
    
    # Convert Object3d labels to format expected by visualizer
    boxes_for_viz = []
    for obj in object3dlabels:
        if obj.type != "DontCare":
            boxes_for_viz.append(obj)
    
    # Visualize scene
    visualizer.visualize_scene(
        points=pc_velo,
        boxes=boxes_for_viz,
        point_cloud_range=point_cloud_range,
        save_path=save_path,
        show_coordinate_frame=True,
        show_ground_grid=True
    )


# Image visualization functions (maintained for compatibility)

def plt_multiimages(images: List[np.ndarray], 
                   objectlabels: List[List[Object3d]], 
                   datasetname: str, 
                   order: int = 1) -> None:
    """Display multiple images with 2D bounding boxes."""
    plt.figure(order, figsize=(16, 9))
    camera_count = len(images)
    
    for count in range(camera_count):
        if datasetname.lower() == 'waymokitti':
            index = waymocameraorder[count]
            pltshow_image_with_boxes(index, images[index], objectlabels[index], [3, 3, count+1])
        elif datasetname.lower() == 'kitti':
            index = count
            pltshow_image_with_boxes(index, images[index], objectlabels[index], [1, 2, count+1])


def pltshow_image_with_boxes(cameraid: int, img: np.ndarray, 
                           objects: List[Object3d], layout: List[int], 
                           cmap=None) -> None:
    """Show image with 2D bounding boxes."""
    ax = plt.subplot(*layout)
    img1 = np.copy(img)
    plt.imshow(img1, cmap=cmap)
    plt.title(cameraname_map[cameraid])
    
    if not objects or len(objects) == 0:
        return
    
    for obj in objects:
        if obj.type == "DontCare":
            continue
        
        box = obj.box2d
        objectclass = obj.type
        
        if objectclass in INSTANCE_Color.keys():
            colorlabel = INSTANCE_Color[objectclass]
            xmin, ymin, xmax, ymax = box
            width = xmax - xmin
            height = ymax - ymin
            
            if height > 0 and width > 0:
                ax.add_patch(patches.Rectangle(
                    xy=(xmin, ymin),
                    width=width,
                    height=height,
                    linewidth=1,
                    edgecolor=colorlabel,
                    facecolor='none'
                ))
                ax.text(xmin, ymin, objectclass, color=colorlabel, fontsize=8)
        else:
            print(f"Object not in KITTI: {objectclass}")
    
    plt.grid(False)
    plt.axis('on')


def main():
    """
    Main function for command-line interface.
    
    Provides the same interface as the original waymokittiall.py but uses Open3D
    for 3D visualization instead of Mayavi.
    """
    parser = argparse.ArgumentParser(description="KITTI/Waymo2KITTI visualization with Open3D")
    parser.add_argument(
        "--root_path", 
        default='/mnt/f/Dataset/DAIR-C/infrastructure-side-point-cloud-kitti/training',
        help="Root folder path"
    )
    parser.add_argument("--index", default="4534", help="File index")
    parser.add_argument("--dataset", default="kitti", help="Dataset name (kitti/waymokitti)")
    parser.add_argument("--camera_count", default=1, type=int, help="Number of cameras used")
    parser.add_argument("--jpgfile", default=True, type=bool, help="Use JPG files")
    parser.add_argument("--headless", action="store_true", help="Run in headless mode")
    parser.add_argument("--save_ply", help="Path to save PLY file")
    parser.add_argument("--point_cloud_range", nargs=6, type=float,
                       default=[-100, -60, -8, 100, 60, 8],
                       help="Point cloud range [xmin ymin zmin xmax ymax zmax]")
    
    args = parser.parse_args()
    
    basedir = args.root_path
    idx = int(args.index)
    camera_count = args.camera_count
    
    camera_index, max_cameracount = datasetinfo(args.dataset)
    
    # File paths
    filename = f"{idx:06d}.png"
    image_folder = f'image_{camera_index}'
    image_files = [os.path.join(basedir, f"image_{i+camera_index}", filename) 
                   for i in range(camera_count)]
    calibration_file = os.path.join(basedir, 'calib', filename.replace('png', 'txt'))
    label_all_file = os.path.join(basedir, 'label_all', filename.replace('png', 'txt'))
    labels_files = [os.path.join(basedir, f"label_{i+camera_index}", filename.replace('png', 'txt')) 
                    for i in range(camera_count)]
    lidar_filename = os.path.join(basedir, 'velodyne', filename.replace('png', 'bin'))
    
    # Load data
    print(f"Loading data for index {idx}...")
    
    # Load LiDAR points
    pc_velo = load_velo_scan(
        lidar_filename, 
        dtype=np.float32, 
        n_vec=4, 
        filterpoints=True, 
        point_cloud_range=args.point_cloud_range
    )
    
    # Load calibration
    calib = getcalibration(args.dataset, calibration_file)
    
    # Load images and labels
    images = load_image(image_files, jpgfile=args.jpgfile)
    objectlabels = read_multi_label(labels_files)
    
    # Display 2D visualizations
    if not args.headless:
        plt_multiimages(images, objectlabels, args.dataset)
        plt.show()
    
    # Load 3D labels
    if args.dataset.lower() == 'waymokitti':
        object3dlabels = read_label(label_all_file)
    elif args.dataset.lower() == 'kitti':
        object3dlabels = objectlabels[0]
    
    # 3D visualization with Open3D
    save_path = args.save_ply if args.save_ply else None
    if args.headless and not save_path:
        save_path = f"scene_{idx:06d}.ply"
    
    visualize_lidar_with_boxes_open3d(
        pc_velo=pc_velo,
        object3dlabels=object3dlabels,
        calib=calib,
        point_cloud_range=args.point_cloud_range,
        save_path=save_path,
        headless=args.headless
    )
    
    print("Visualization complete!")


if __name__ == "__main__":
    main()